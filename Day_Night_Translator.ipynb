{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day-Night Translator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkk4Dz+9B/loQo5Rb7Dfw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ageraustine/Day-Night-Image-CycleGANs/blob/master/Day_Night_Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G12G4FxN4iNH",
        "outputId": "e4b55baf-9358-4aa2-d68c-8bbeee065c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA FETCHING"
      ],
      "metadata": {
        "id": "GxJTdA82q5FF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic6m0Fqsqui4"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/datasets/raman77768/day-time-and-night-time-road-images/download\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "url = \"https://storage.googleapis.com/kaggle-data-sets/801580/1383092/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220502%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220502T074036Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=17a60bdb553871ad7ea563dcf664f3962a19670731e9e5df7a194c8567fa33c963ccc38d93a9478204265ec6755dc05f001706d71860a8544f5e4f248cfc14d4c9113484f1dc45a7ed1781f006e00c45efecc726ed35eb614748a2fb0af1ad35a8150fcaab59b1cc9223fd4804aa55f5de2672a16e2c4140cb25dab5213670837f117a69d1d67e67e534a63285ba5dee9678bceb5c4c53f6f28c58b083079aea142c08b9e98116b7a610470710063c25f0cd205ebd043208893cb97c4e68cb9d0b5c0cbc58cce4020eb1dc8c896700cd7d7a567752c948c97db87bb7fed09c2cc3a59d171f2d4a24affb3cede1ffe7e2cf3287eef2491f6c330f476e237bc8a1\"\n",
        "data_zpfile_path = os.path.join(os.getcwd(), \"data.tar.gz\")\n",
        "\n",
        "def download():\n",
        "  if not os.path.exists(data_zpfile_path):\n",
        "    keras.utils.get_file(fname=data_zpfile_path, origin=url)\n",
        "\n",
        "def extract():\n",
        "  if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data\")\n",
        "    extpath = os.path.join(os.getcwd(), \"data\")\n",
        "    with zipfile.ZipFile(data_zpfile_path, \"r\") as zp:\n",
        "      zp.extractall(extpath)\n",
        "   \n",
        "\n",
        "def get_data():\n",
        "  download()\n",
        "  extract()\n",
        "\n",
        "get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET PREPARATION"
      ],
      "metadata": {
        "id": "nFzytlxnyz3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "night_images_paths = [\n",
        "                      os.path.join(os.getcwd(), \"data/night time road images/night time road images/\", x)\n",
        "                      for x in os.listdir(\"data/night time road images/night time road images/\")\n",
        "                      ]\n",
        "day_images_paths = [\n",
        "                    os.path.join(os.getcwd(), \"data/day light road images/day light road images/\", x)\n",
        "                    for x in os.listdir(\"data/day light road images/day light road images/\")\n",
        "                   ]\n",
        "# Define the standard image size.\n",
        "orig_img_size = (286, 286)\n",
        "# Size of the random crops to be used during training.\n",
        "input_img_size = (256, 256, 3)\n",
        "# Weights initializer for the layers.\n",
        "kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "# Gamma initializer for instance normalization.\n",
        "gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "buffer_size = 256\n",
        "batch_size = 1\n",
        "\n",
        "def normalize_img(img):\n",
        "    img = tf.cast(img, dtype=tf.float32)\n",
        "    # Map values in the range [-1, 1]\n",
        "    return (img / 127.5) - 1.0\n",
        "\n",
        "def preprocess_train_image(img):\n",
        "    # Random flip\n",
        "    img = tf.image.random_flip_left_right(img)\n",
        "    # Resize to the original size first\n",
        "    img = tf.image.resize(img, [*orig_img_size])\n",
        "    # Random crop to 256X256\n",
        "    img = tf.image.random_crop(img, size=[*input_img_size])\n",
        "    # Normalize the pixel values in the range [-1, 1]\n",
        "    img = normalize_img(img)\n",
        "    return img\n",
        "\n",
        "def preprocess_test_image(img):\n",
        "    # Only resizing and normalization for the test images.\n",
        "    img = tf.image.resize(img, [*input_img_size])\n",
        "    img = normalize_img(img)\n",
        "    return img\n",
        "\n",
        "def load_train_images(image_paths):\n",
        "  imgs = []\n",
        "  for x in image_paths:\n",
        "    image = tf.io.read_file(x)\n",
        "    image = tf.image.decode_jpeg(image,3)\n",
        "    image = preprocess_train_image(image)\n",
        "    imgs.append(image)\n",
        "  return imgs\n",
        "\n",
        "def load_test_images(image_paths):\n",
        "  imgs = []\n",
        "  for x in image_paths:\n",
        "    image = tf.io.read_file(x)\n",
        "    image = tf.image.decode_jpeg(image,3)\n",
        "    image = preprocess_test_image(x)\n",
        "    imgs.append(image)\n",
        "  return imgs\n",
        "\n",
        "total_index = len(night_images_paths)\n",
        "split_index = math.floor(0.1*total_index)\n",
        "\n",
        "# train images paths\n",
        "train_day_paths = day_images_paths[:split_index]\n",
        "train_night_paths = night_images_paths[:split_index]\n",
        "\n",
        "# test images paths\n",
        "test_day_paths = day_images_paths[split_index:total_index]\n",
        "test_night_paths = night_images_paths[split_index:total_index]"
      ],
      "metadata": {
        "id": "v7c8lf-Hy3ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_day = load_train_images(train_day_paths)\n",
        "train_A_ds = tf.data.Dataset.from_tensors(train_day)\n",
        " "
      ],
      "metadata": {
        "id": "A-6PdnntETsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_night = load_train_images(train_night_paths)\n",
        "train_B_ds = tf.data.Dataset.from_tensors(train_night)\n",
        "train_B_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG9HFnapFT48",
        "outputId": "04c028a8-9dfd-40fd-cd7c-8ef5ced4aed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorDataset element_spec=TensorSpec(shape=(1696, 256, 256, 3), dtype=tf.float32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE BUILDING BLOCKS OF OUR CYCLEGAN"
      ],
      "metadata": {
        "id": "XLmrPVDPK3Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReflectionPadding(layers.Layer):\n",
        "  def __init__(self, padding = (1, 1), **kwargs):\n",
        "      self.padding = tuple(padding)\n",
        "      super(ReflectionPadding, self).__init__(**kwargs)\n",
        "\n",
        "  def call(self, input_tensor, mask=None):\n",
        "    padding_width, padding_height = self.padding\n",
        "    padding_tensor = [\n",
        "                      [0,0],\n",
        "                      [padding_height, padding_height],\n",
        "                      [padding_width, padding_width],\n",
        "                      [0,0] ]\n",
        "    return tf.pad(input_tensor, padding_tensor, mode='REFLECT')\n",
        "\n",
        "def residual_block(\n",
        "    x, \n",
        "    activation, \n",
        "    kernel_initializer= kernel_init, \n",
        "    kernel_size=(3,3), \n",
        "    padding=\"valid\", \n",
        "    strides=(1, 1), \n",
        "    gamma_initializer=gamma_init, \n",
        "    use_bias=False):\n",
        "  dim = x.shape[-1]\n",
        "  input_tensor = x\n",
        "  x = ReflectionPadding()(input_tensor)\n",
        "  x = layers.Conv2D(dim, kernel_size, strides=strides, padding=padding, kernel_initializer=kernel_initializer, use_bias=use_bias)\n",
        "  x = tfa.layers.InstanceNormalization(gamma_initializer = gamma_initializer)(x)\n",
        "  x = activation(x)\n",
        "  x = ReflectionPadding()(x)\n",
        "  x = layers.Conv2D(dim, kernel_size, strides=strides, padding=padding, kernel_initializer=kernel_initializer, use_bias=use_bias)(x)\n",
        "  x = tfa.layers.InstanceNormalization(gamma_initializer = gamma_initializer)(x)\n",
        "  x = layers.add([input_tensor, x])\n",
        "  return x\n",
        "\n",
        "def downsample(\n",
        "    x, \n",
        "    filters, \n",
        "    activation, \n",
        "    kernel_size=(3,3), \n",
        "    strides=(2,2), \n",
        "    kernel_initializer=kernel_init, \n",
        "    padding=\"same\", \n",
        "    gamma_initializer=gamma_init, \n",
        "    use_bias= False ):\n",
        "  x = layers.Conv2D(filters,kernel_size, strides=strides, kernel_initializer=kernel_initializer, padding=padding, use_bias=use_bias)(x)\n",
        "  x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "  if activation:\n",
        "    x = activation(x)\n",
        "  return x\n",
        "\n",
        "def upsample(\n",
        "        x, \n",
        "        filters, \n",
        "        activation, \n",
        "        kernel_size=(3,3), \n",
        "        strides=(2,2), \n",
        "        kernel_initializer=kernel_init, \n",
        "        padding=\"same\", \n",
        "        gamma_initializer=gamma_init, \n",
        "        use_bias= False):\n",
        "  x = layers.Conv2DTranspose(filters,kernel_size, strides=strides, kernel_initializer=kernel_initializer, padding=padding, use_bias=use_bias)(x)\n",
        "  x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "  if activation:\n",
        "    x = activation(x)\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "IeFLRPOQK80S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_generator(\n",
        "        filters=64, \n",
        "        num_downsampling_blocks =2, \n",
        "        num_upsampling_blocks=9, \n",
        "        num_residual_blocks=2, \n",
        "        gamma_initializer=gamma_init, \n",
        "        name=None, \n",
        "        ):\n",
        "  img_input = layers.Input(shape=input_img_size, name=name)\n",
        "  x = ReflectionPadding(padding=(3,3))(img_input)\n",
        "  x = layers.Conv2D(filters, (7,7), kernel_initializer=kernel_init, use_bias=False)(x)\n",
        "  x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "  #downsampling\n",
        "  for _ in range(num_downsampling_blocks):\n",
        "    filters *= 2\n",
        "    x = downsample(x, filters=filters, activation=layers.Activation(\"relu\"))\n",
        "   # residual block  \n",
        "  for _ in range(num_residual_blocks):\n",
        "    x = residual_block(x, activation=layers.Activation(\"relu\"))\n",
        "  # upsampling blocks\n",
        "  for _ in range(num_upsampling_blocks):\n",
        "    filters //= 2\n",
        "    x = upsample(x, filters= filters, activation=layers.Activation(\"relu\"))\n",
        "  # final block\n",
        "  x = ReflectionPadding(padding=(3,3))(x)\n",
        "  x = layers.Conv2D(3, (7,7), padding=\"valid\")(x)\n",
        "  x = layers.Activation(\"tanh\")(x)\n",
        "\n",
        "  model = keras.models.Model(img_input, x, name=name)\n",
        "  return model"
      ],
      "metadata": {
        "id": "RhfLSXHTVWFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator(filters = 64,num_downsampling_blocks= 3, kernel_initializer=kernel_init, name=None):\n",
        "  img_input = layers.Input(shape=input_img_size, image = name + \"_img_input\")\n",
        "  x = layers.Conv2D(filters, (4,4), strides=(2, 2), padding=\"same\", kernel_initializer=kernel_initializer)(img_input)\n",
        "  x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "  num_filters = filters \n",
        "  for block_num in range(num_downsampling_blocks):\n",
        "    num_filters *= 2\n",
        "    if block_num < 2:\n",
        "      x = downsample(x, num_filters, activation= layers.LeakyReLU(0.2), kernel_size=(4,4), strides=(2, 2))\n",
        "    else:\n",
        "      x = downsample(x, num_filters, activation= layers.LeakyReLU(0.2), kernel_size=(4,4), strides=(1, 1))\n",
        "  x = layers.Conv2D(1, (4, 4), strides=(1,1), padding=\"same\", kernel_initializer=kernel_initializer)(x)\n",
        "\n",
        "  model = keras.models.Model(inputs=img_input, outputs=x, name=name)\n",
        "  return model\n",
        "\n",
        "# declare the generators\n",
        "gen_G = resnet_generator(name=\"generator_G\")\n",
        "gen_F = resnet_generator(name=\"generator_F\")\n",
        "\n",
        "# declare the discriminators\n",
        "disc_X = get_discriminator(name=\"discriminator_X\")\n",
        "disc_Y = get_discriminator(name=\"discriminator_Y\")"
      ],
      "metadata": {
        "id": "R171z-XVbPoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGAN(layers.Layer):\n",
        "  def __init__(\n",
        "          self, \n",
        "          generator_G, \n",
        "          generator_F, \n",
        "          discriminator_X, \n",
        "          discriminator_Y, \n",
        "          lambda_cycle=10, \n",
        "          lambda_identity=0.5 \n",
        "          ):\n",
        "    self.generator_G = generator_G\n",
        "    self.generator_F = generator_F\n",
        "    self.discriminator_X = discriminator_X\n",
        "    self.discriminator_Y = discriminator_Y\n",
        "    self.lambda_cycle = lambda_cycle\n",
        "    self.lambda_identity = lambda_identity\n",
        "\n",
        "  def compile(self, gen_G_optimizer, gen_F_optimizer, disc_optimizer_X, disc_optimizer_Y, gen_loss_fn, disc_loss_fn):\n",
        "    super(CycleGAN, self).compile()\n",
        "    self.gen_G_optimizer = gen_G_optimizer\n",
        "    self.gen_F_optimizer = gen_F_optimizer\n",
        "    self.disc_optimizer_X = disc_optimizer_X\n",
        "    self.disc_optimize_Y = disc_optimizer_Y\n",
        "    self.gen_loss_fn = gen_loss_fn\n",
        "    self.disc_loss_fn = disc_loss_fn\n",
        "    self.cycle_loss_fn = keras.losses.MeanAbsoluteError()\n",
        "    self.identity_loss_fn = keras.losses.MeanAbsoluteError()\n",
        "\n",
        "  def train_step(self, batch_data):\n",
        "    real_x, real_y = batch_data\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # x to y\n",
        "      fake_y = self.generator_G(real_x, training=True)\n",
        "      # y to x\n",
        "      fake_x = self.generator_F(real_y, training= True)\n",
        "      # Reconstructing fake outputs back to original\n",
        "      reconstructed_y = self.generator_G(fake_x, training=True)\n",
        "      reconstructed_x = self.generator_F(fake_y, training=True)\n",
        "      # Identity mapping\n",
        "      same_x = self.generator_F(real_x, training= True)\n",
        "      same_y = self.generator_G(real_y, training=True)\n",
        "      #Discriminator output\n",
        "      disc_real_x = self.discriminator_X(real_x, training=True)\n",
        "      disc_fake_x = self.discriminator_X(fake_x, training=True)\n",
        "\n",
        "      disc_real_y = self.discriminator_Y(real_y, training=True)\n",
        "      disc_fake_y = self.discriminator_Y(fake_y, training=True)\n",
        "\n",
        "      # Generator Adversarial loss\n",
        "      gen_G_loss = self.gen_loss_fn(disc_fake_y)\n",
        "      gen_F_loss = self.gen_loss_fn(disc_fake_x)\n",
        "      # Generator cycle loss\n",
        "      cycle_loss_G = self.cycle_loss_fn(real_y, reconstructed_y)*self.lambda_cycle\n",
        "      cycle_loss_F = self.cycle_loss_fn(real_x, reconstructed_x)*self.lambda_cycle \n",
        "      # generator identity loss\n",
        "      id_loss_G = (\n",
        "          self.identity_loss_fn(real_y, same_y)\n",
        "          *self.lambda_cycle\n",
        "          *self.lambda_identity\n",
        "      )\n",
        "      id_loss_F = (\n",
        "          self.identity_loss_fn(real_x, same_x)\n",
        "          *self.lambda_cycle\n",
        "          *self.lambda_identity\n",
        "      )\n",
        "      # Total generator loss\n",
        "      total_loss_G = gen_G_loss + cycle_loss_G + id_loss_G\n",
        "      total_loss_F = gen_F_loss + cycle_loss_F + id_loss_F\n",
        "      # Discriminator loss\n",
        "      disc_X_loss = self.disc_loss_fn(disc_real_x, disc_fake_x)\n",
        "      disc_Y_loss = self.disc_loss_fn(disc_real_y, disc_fake_y)\n",
        "\n",
        "    #Get gradients for the generator\n",
        "    grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)\n",
        "    grads_F = tape.gradient(total_loss_F, self.gen_F.trainable_variables)\n",
        "    # Get gradients for the dicriminator\n",
        "    disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)\n",
        "    disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)\n",
        "    # Update the weights of the generators \n",
        "    self.gen_G_optimizer.apply_gradients(\n",
        "            zip(grads_G, self.gen_G.trainable_variables)\n",
        "        )\n",
        "    self.gen_F_optimizer.apply_gradients(\n",
        "            zip(grads_F, self.gen_F.trainable_variables)\n",
        "        )\n",
        "    # Update the weights of the dicriminators\n",
        "    self.disc_X_optimizer.apply_gradients(\n",
        "            zip(disc_X_grads, self.disc_X.trainable_variables)\n",
        "        )\n",
        "    self.disc_Y_optimizer.apply_gradients(\n",
        "            zip(disc_Y_grads, self.disc_Y.trainable_variables)\n",
        "        )\n",
        "    return {\n",
        "            \"G_loss\": total_loss_G,\n",
        "            \"F_loss\": total_loss_F,\n",
        "            \"D_X_loss\": disc_X_loss,\n",
        "            \"D_Y_loss\": disc_Y_loss,\n",
        "        }"
      ],
      "metadata": {
        "id": "dpr2zKddnsSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Callback for periodically saving the model"
      ],
      "metadata": {
        "id": "6TR4A61_fSph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "  def __init__(self, num_imgs=4):\n",
        "    self.num_imgs = num_imgs\n",
        "  \n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    _, ax = plt.subplots(4, 2, figsize=(12, 12))\n",
        "    for i, img in enumerate(train_A_ds.take(self.num_img)):\n",
        "      prediction = self.model.gen_G(img)[0].numpy()\n",
        "      prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
        "      img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
        "\n",
        "      ax[i, 0].imshow(img)\n",
        "      ax[i, 1].imshow(prediction)\n",
        "      ax[i, 0].set_title(\"Input image\")\n",
        "      ax[i, 1].set_title(\"Translated image\")\n",
        "      ax[i, 0].axis(\"off\")\n",
        "      ax[i, 1].axis(\"off\")\n",
        "\n",
        "      prediction = keras.preprocessing.image.array_to_img(prediction)\n",
        "      prediction.save(\n",
        "                \"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch + 1)\n",
        "            )\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "hzfRUo5Drb0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "cNXK_4UHfb0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function for evaluating adversarial loss\n",
        "adv_loss = keras.losses.MeanSquaredError()\n",
        "\n",
        "def generator_loss_fn(fake):\n",
        "  fake_loss = adv_loss(tf.ones_like(fake), fake)\n",
        "  return fake_loss\n",
        "\n",
        "def discriminator_loss_fn(real, fake):\n",
        "  real_loss = adv_loss(tf.ones_like(real), real)\n",
        "  fake_loss= adv_loss(tf.zeros_like(fake), fake)\n",
        "  return (real_loss + fake_loss)*0.5\n",
        "\n",
        "# Create cycle gan model\n",
        "cycle_gan_model = CycleGAN(\n",
        "    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "cycle_gan_model.compile(\n",
        "    gen_G_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
        "    gen_F_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
        "    disc_X_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
        "    disc_Y_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
        "    gen_loss_fn=generator_loss_fn,\n",
        "    disc_loss_fn=discriminator_loss_fn,\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "plotter = GANMonitor()\n",
        "checkpoint_filepath = \"./model_checkpoints/cyclegan_checkpoints.{epoch:03d}\"\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath\n",
        ")\n",
        "\n",
        "cycle_gan_model.fit(\n",
        "    tf.data.Dataset.zip((train_A_ds, train_B_ds)),\n",
        "    epochs=1,\n",
        "    callbacks=[plotter, model_checkpoint_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "gs0LVWMZfeSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}